%==============================================================================
\chapter{Introdução}\label{sec_introducao}
%==============================================================================


% cenário
\red{Durante a pandemia de \textit{coronavirus disease 2019} (COVID-19) os sistemas de saúde do mundo inteiro enfrentam problemas quanto a disponibilidade e alocação de recursos como respiradores e leitos de UTI (Unidade de Terapia Intensiva) \cite{latif2020leveraging} \cite{ranney2020critical}. Políticas e decisões críticas estão sendo tomadas quanto a priorização de pacientes com a doença e, em países como o Brasil, existem regras que definem quem tem direito a leitos de UTI. Em alguns lugares, devido a urgência e falta de dados mais precisos, a política tem sido priorizar as pessoas mais jovens para a ocupação dos leitos de UTI\footnote[1]{https://www.nsctotal.com.br/colunistas/dagmara-spautz/estado-oficializa-criterio-que-da-prioridade-a-mais-jovens-e-saudaveis}. Em estados como o Rio Grande do Sul, não há leitos para todos os pacientes em estado grave\footnote[2]{https://www.estado.rs.gov.br/mesmo-com-expansao-de-leitos-45-rodada-confirma-pressao-sobre-capacidade-hospitalar-e-rs-em-bandeira-preta}, consequentemente, é preciso colocar em prática políticas de priorização da alocação dos leitos com base no estado clínico do paciente.}

\red{Estudos mostram que modelos de aprendizagem de máquina (\textit{machine learning}) conseguem predizer a chance de óbito de um paciente positivo para COVID-19 com até 0,99 de pontuação AUC-ROC (\textit{Area Under the Curve - Receiver Operating Charachteristic Curve})  \cite{wynants2020prediction}.
% problema (Desafio de modelos): modelos, características e métricas
Por se tratar de um contexto crítico (pandemia e risco de vida), os modelos preditivos devem ser robustos, seguros e transparentes, sem comprometer a ética.  Um dos principais desafios é desenvolver e garantir a credibilidade destes modelos.}

% modelos
%\red{No contexto de análise preditiva, o estado da arte aponta que o algoritmo Floresta Aleatória (\textit{Random Forest}) é o mais frequentemente utilizado (Seção \ref{sec_classificacao_de_risco}). Isto ocorre devido ao fato deste método ser considerado acurado e robusto pois que conta com um alto número de árvores de decisão \cite{james2013statistical}) no processo, por não sofrer com sobreajuste e pelo seu auxílio na classificação da importância das características \cite{breiman2001random}.}

% características
%\red{Com relação as características utilizadas para ``alimentar'' o modelo, foi possível constatar que as mais utilizadas para treinamento são dados clínicos (\textit{e.g.}, sintomas e comorbidades), dados demográficos (\textit{e.g.}, idade, sexo e país de origem) \cite{iwendi2020covid, pourhomayoun2020predicting, yadaw2020clinical, chowdhury2020early, dun2020machine}, dados laboratoriais (\textit{e.g.}, amostras de sangue) \cite{cheng2020using, gao2020machine, chowdhury2020early, casiraghi2020explainable} e características radiológicas (\textit{e.g.}, imagens de radiografia) \cite{casiraghi2020explainable}. 
%Tanto os tipos de dados quanto a quantidade de características utilizadas nos estudos variam significativamente, indo de 3 \cite{yadaw2020clinical} a 99 \cite{cheng2020using} características. Por fim, ROC-AUC foi a métrica de avaliação mais utilizada nos estudos (ver detalhes na Seção \ref{sec_classificacao_de_risco})}

% problemática com população
\blue{Muitos estudos e propostas de soluções para classificação de risco refletem dificuldades nas suas aplicações ou até mesmo em como podem auxiliar no contexto médico \cite{wynants2020prediction}. Diversos modelos contém alto risco de enviesamento (\textit{i.e.}, modelo não generalista) devido ao desenvolvimento baseado em amostras pequenas da população (\textit{e.g.}, dados de apenas um hospital), métricas de avaliação inadequadas (\textit{e.g.}, acurácia para dados desbalanceados), ou pobreza de detalhes sobre o desenvolvimento e objetivo do modelo (\textit{e.g.}, omissão dos métodos utilizados) \cite{wynants2020prediction}. Devido a alta variabilidade climática, cultural e racial entre diferentes países e populações \cite{assaf2020utilization, cheng2020using, zhao2020prediction, casiraghi2020explainable} é necessário o desenvolvimento de uma solução que utilize dados de populações pouco exploradas, como é o caso do Brasil, além de utilizar métricas para avaliação do desempenho de modelos com dados desbalanceados. Por fim, para mitigar a falta de detalhes na explanação do estudo, deve-se utilizar guias que auxiliem a relatar de maneira transparente o desenvolvimento do modelo como o STARD (\textit{Standards for Reporting of Diagnostic Accuracy}) \cite{bossuyt2003stard} e o TRIPOD (\textit{Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis}) \cite{collins2015tripod}. } 

%métricas em dados desbalanceados
%\red{A acurácia é a métrica mais comumente utilizada em problemas de %classificação, embora nem sempre seja adequada, sendo potencialmente perigosa %quando usada em conjunto de dados desbalanceados \cite{guo2008class}. Se 95\% %dos dados pertencerem à majoritária (negativa/recuperação), é fácil ver que um %classificador ingênuo terá acurácia de 95\%, simplesmente prevendo a classe %negativa sempre, o que não é aceitável na prática, pois não estaremos %identificando os exemplos pertencentes à classe minoritária (positiva/óbito). 
%\red{No contexto do presente trabalho, a proporção de casos recuperados por casos de óbito no estado do Rio Grande do Sul é de aproximadamente 40:1\footnote[3]{https://covid.saude.gov.br/} (quarenta para um), para tal, precisamos utilizar métricas alternativas como a ROC-AUC, que foi a métrica mais utilizada em estudos recentes (ver detalhes na Seção \ref{sec_classificacao_de_risco}). Contudo, há métricas de avaliação de modelos de classificação binária mais informativas e com menos propensão a invesamento à classe majoritária, como é o caso da visualização da Precisão-revocação \cite{saito2015precision}.}

% objetivo do trabalho
\blue{Neste trabalho, propomos um modelo preditivo baseado em florestas aleatórias \cite{breiman2001random} para classificação de risco de óbito para pacientes confirmados de COVID-19 no estado do Rio Grande do Sul/Brasil. Utilizamos a pontuação AUC-ROC para avaliar a performance do modelo. Este é um indicador importante pois nos fornece uma medida da precisão total do modelo independente de um limiar particular \cite{fawcett2006roc}. O desenvolvimento do modelo é explanado utilizando o guia TRIPOD para atenuar o risco da falta de detalhes. Utilizamos também da validação cruzada 5-\textit{fold} para validar internamente o modelo e, desta forma, reduzir o risco de enviesamento.} %temos um modelo preditivo com menor risco de enviesamento e mais robusto (\textit{i.e} mais acurado), aliado à aplicação dos testes sobre uma população ainda pouco explorada pelos estudos (Rio Grande do Sul).

% metodologia
%\red{Para atingir o objetivo, o trabalho foi dividido em quatro etapas. A primeira etapa consiste na aquisição e análise dos dados. Na segunda etapa é realizada a limpeza e mineração de dados para a eliminação das inconsistências e dados faltantes. Na terceira etapa, o pré-processamento dos dados que antecederam a quarta etapa, que consistiu na implementação e validação do modelo preditivo.}

\red{O restante deste trabalho está organizado como segue. 
Na Seção \ref{sec_classificacao_de_risco} é apresentado o estado da arte do aprendizado de máquina aplicado ao combate da pandemia. Na Seção  \ref{sec_metodologia} é discutido o projeto do estudo, a aquisição dos dados e a construção do modelo de prognóstico. Na Seção \ref{sec_resultados} avaliamos a performance do modelo construído, bem como a sua interpretabilidade. Por fim, na Seção \ref{sec_discussao} há a discussão geral sobre as contribuições e limites do presente estudo.}